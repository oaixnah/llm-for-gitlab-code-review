#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è¿è¡Œè„šæœ¬

æä¾›å¤šç§æµ‹è¯•è¿è¡Œé€‰é¡¹å’ŒæŠ¥å‘Šç”ŸæˆåŠŸèƒ½ã€‚
"""

import os
import sys
import argparse
import subprocess
import time
from pathlib import Path


def run_command(cmd, description=""):
    """è¿è¡Œå‘½ä»¤å¹¶å¤„ç†ç»“æœ"""
    if description:
        print(f"\n{'='*60}")
        print(f"æ‰§è¡Œ: {description}")
        print(f"å‘½ä»¤: {' '.join(cmd)}")
        print(f"{'='*60}")
    
    start_time = time.time()
    
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            check=False
        )
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"\næ‰§è¡Œæ—¶é—´: {duration:.2f} ç§’")
        
        if result.stdout:
            print("\næ ‡å‡†è¾“å‡º:")
            print(result.stdout)
        
        if result.stderr:
            print("\næ ‡å‡†é”™è¯¯:")
            print(result.stderr)
        
        if result.returncode != 0:
            print(f"\nâŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œé€€å‡ºç : {result.returncode}")
            return False
        else:
            print(f"\nâœ… å‘½ä»¤æ‰§è¡ŒæˆåŠŸ")
            return True
            
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå‘½ä»¤æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False


def install_dependencies():
    """å®‰è£…æµ‹è¯•ä¾èµ–"""
    print("\nğŸ”§ å®‰è£…æµ‹è¯•ä¾èµ–...")
    
    # åŸºç¡€æµ‹è¯•ä¾èµ–
    test_deps = [
        "pytest>=7.0.0",
        "pytest-cov>=4.0.0",
        "pytest-mock>=3.10.0",
        "pytest-asyncio>=0.21.0",
        "pytest-xdist>=3.0.0",
        "pytest-html>=3.1.0",
        "pytest-json-report>=1.5.0",
        "pytest-benchmark>=4.0.0",
        "pytest-timeout>=2.1.0",
        "coverage>=7.0.0",
        "psutil>=5.9.0",  # ç”¨äºæ€§èƒ½æµ‹è¯•
    ]
    
    for dep in test_deps:
        cmd = [sys.executable, "-m", "pip", "install", dep]
        if not run_command(cmd, f"å®‰è£… {dep}"):
            print(f"âš ï¸  å®‰è£… {dep} å¤±è´¥ï¼Œç»§ç»­å®‰è£…å…¶ä»–ä¾èµ–...")
    
    print("\nâœ… ä¾èµ–å®‰è£…å®Œæˆ")


def run_unit_tests(verbose=False, coverage=True):
    """è¿è¡Œå•å…ƒæµ‹è¯•"""
    cmd = [sys.executable, "-m", "pytest"]
    
    # åŸºç¡€å‚æ•°
    cmd.extend([
        "tests/test_config.py",
        "tests/test_models.py",
        "tests/test_utils.py",
        "tests/test_llm.py",
        "tests/test_curd.py",
        "-m", "not integration and not performance"
    ])
    
    if verbose:
        cmd.append("-v")
    
    if coverage:
        cmd.extend([
            "--cov=config",
            "--cov=models",
            "--cov=utils",
            "--cov=llm",
            "--cov=curd",
            "--cov-report=html:reports/unit_coverage",
            "--cov-report=term-missing"
        ])
    
    return run_command(cmd, "å•å…ƒæµ‹è¯•")


def run_integration_tests(verbose=False):
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    cmd = [sys.executable, "-m", "pytest"]
    
    cmd.extend([
        "tests/test_review_manager.py",
        "tests/test_main.py",
        "-m", "not performance"
    ])
    
    if verbose:
        cmd.append("-v")
    
    cmd.extend([
        "--html=reports/integration_report.html",
        "--self-contained-html"
    ])
    
    return run_command(cmd, "é›†æˆæµ‹è¯•")


def run_performance_tests(verbose=False):
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    cmd = [sys.executable, "-m", "pytest"]
    
    cmd.extend([
        "tests/test_performance.py",
        "-m", "performance",
        "--benchmark-only",
        "--benchmark-sort=mean",
        "--benchmark-json=reports/benchmark.json"
    ])
    
    if verbose:
        cmd.append("-v")
    
    return run_command(cmd, "æ€§èƒ½æµ‹è¯•")


def run_all_tests(verbose=False, coverage=True, parallel=False):
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    cmd = [sys.executable, "-m", "pytest"]
    
    cmd.extend(["tests/"])
    
    if verbose:
        cmd.append("-v")
    
    if parallel:
        cmd.extend(["-n", "auto"])
    
    if coverage:
        cmd.extend([
            "--cov=.",
            "--cov-report=html:reports/full_coverage",
            "--cov-report=term-missing",
            "--cov-report=xml:reports/coverage.xml"
        ])
    
    cmd.extend([
        "--html=reports/full_report.html",
        "--self-contained-html",
        "--json-report",
        "--json-report-file=reports/test_results.json"
    ])
    
    return run_command(cmd, "å®Œæ•´æµ‹è¯•å¥—ä»¶")


def run_specific_test(test_path, verbose=False):
    """è¿è¡Œç‰¹å®šæµ‹è¯•"""
    cmd = [sys.executable, "-m", "pytest", test_path]
    
    if verbose:
        cmd.append("-v")
    
    return run_command(cmd, f"ç‰¹å®šæµ‹è¯•: {test_path}")


def run_linting():
    """è¿è¡Œä»£ç æ£€æŸ¥"""
    print("\nğŸ” è¿è¡Œä»£ç æ£€æŸ¥...")
    
    # æ£€æŸ¥æ˜¯å¦å®‰è£…äº† linting å·¥å…·
    linting_tools = {
        "flake8": "flake8>=5.0.0",
        "black": "black>=22.0.0",
        "isort": "isort>=5.10.0",
        "mypy": "mypy>=0.991"
    }
    
    for tool, package in linting_tools.items():
        try:
            subprocess.run([tool, "--version"], capture_output=True, check=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            print(f"å®‰è£… {tool}...")
            subprocess.run([sys.executable, "-m", "pip", "install", package])
    
    success = True
    
    # è¿è¡Œ flake8
    if not run_command(["flake8", ".", "--max-line-length=88", "--extend-ignore=E203,W503"], "Flake8 ä»£ç æ£€æŸ¥"):
        success = False
    
    # è¿è¡Œ black æ£€æŸ¥
    if not run_command(["black", "--check", "--diff", "."], "Black æ ¼å¼æ£€æŸ¥"):
        success = False
    
    # è¿è¡Œ isort æ£€æŸ¥
    if not run_command(["isort", "--check-only", "--diff", "."], "Import æ’åºæ£€æŸ¥"):
        success = False
    
    # è¿è¡Œ mypyï¼ˆå¯é€‰ï¼‰
    if Path("mypy.ini").exists() or Path(".mypy.ini").exists():
        run_command(["mypy", "."], "MyPy ç±»å‹æ£€æŸ¥")
    
    return success


def format_code():
    """æ ¼å¼åŒ–ä»£ç """
    print("\nğŸ¨ æ ¼å¼åŒ–ä»£ç ...")
    
    # å®‰è£…æ ¼å¼åŒ–å·¥å…·
    subprocess.run([sys.executable, "-m", "pip", "install", "black>=22.0.0", "isort>=5.10.0"])
    
    # è¿è¡Œ black
    run_command(["black", "."], "Black ä»£ç æ ¼å¼åŒ–")
    
    # è¿è¡Œ isort
    run_command(["isort", "."], "Import æ’åº")
    
    print("\nâœ… ä»£ç æ ¼å¼åŒ–å®Œæˆ")


def generate_test_report():
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šæ‘˜è¦"""
    print("\nğŸ“Š ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šæ‘˜è¦...")
    
    reports_dir = Path("reports")
    if not reports_dir.exists():
        print("âŒ æŠ¥å‘Šç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œæµ‹è¯•")
        return
    
    print(f"\nğŸ“ æµ‹è¯•æŠ¥å‘Šä½ç½®: {reports_dir.absolute()}")
    
    # åˆ—å‡ºç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶
    report_files = {
        "full_report.html": "å®Œæ•´æµ‹è¯•æŠ¥å‘Š",
        "unit_coverage/index.html": "å•å…ƒæµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š",
        "full_coverage/index.html": "å®Œæ•´è¦†ç›–ç‡æŠ¥å‘Š",
        "integration_report.html": "é›†æˆæµ‹è¯•æŠ¥å‘Š",
        "benchmark.json": "æ€§èƒ½æµ‹è¯•ç»“æœ",
        "test_results.json": "æµ‹è¯•ç»“æœ JSON",
        "coverage.xml": "è¦†ç›–ç‡ XML æŠ¥å‘Š"
    }
    
    print("\nğŸ“‹ å¯ç”¨æŠ¥å‘Š:")
    for file_path, description in report_files.items():
        full_path = reports_dir / file_path
        if full_path.exists():
            print(f"  âœ… {description}: {full_path}")
        else:
            print(f"  âŒ {description}: æœªç”Ÿæˆ")


def setup_test_environment():
    """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
    print("\nğŸ—ï¸  è®¾ç½®æµ‹è¯•ç¯å¢ƒ...")
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    directories = ["reports", "logs", ".pytest_cache"]
    for directory in directories:
        Path(directory).mkdir(exist_ok=True)
        print(f"  ğŸ“ åˆ›å»ºç›®å½•: {directory}")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    test_env_vars = {
        "TESTING": "true",
        "LOG_LEVEL": "DEBUG",
        "DATABASE_URL": "sqlite:///:memory:"
    }
    
    for key, value in test_env_vars.items():
        os.environ[key] = value
        print(f"  ğŸ”§ è®¾ç½®ç¯å¢ƒå˜é‡: {key}={value}")
    
    print("\nâœ… æµ‹è¯•ç¯å¢ƒè®¾ç½®å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="GitLab Code Review LLM Service æµ‹è¯•è¿è¡Œå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python run_tests.py --all                    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
  python run_tests.py --unit                   # åªè¿è¡Œå•å…ƒæµ‹è¯•
  python run_tests.py --integration            # åªè¿è¡Œé›†æˆæµ‹è¯•
  python run_tests.py --performance            # åªè¿è¡Œæ€§èƒ½æµ‹è¯•
  python run_tests.py --lint                   # è¿è¡Œä»£ç æ£€æŸ¥
  python run_tests.py --format                 # æ ¼å¼åŒ–ä»£ç 
  python run_tests.py --install-deps           # å®‰è£…æµ‹è¯•ä¾èµ–
  python run_tests.py --test tests/test_*.py   # è¿è¡Œç‰¹å®šæµ‹è¯•
        """
    )
    
    # æµ‹è¯•ç±»å‹é€‰é¡¹
    test_group = parser.add_mutually_exclusive_group()
    test_group.add_argument("--all", action="store_true", help="è¿è¡Œæ‰€æœ‰æµ‹è¯•")
    test_group.add_argument("--unit", action="store_true", help="è¿è¡Œå•å…ƒæµ‹è¯•")
    test_group.add_argument("--integration", action="store_true", help="è¿è¡Œé›†æˆæµ‹è¯•")
    test_group.add_argument("--performance", action="store_true", help="è¿è¡Œæ€§èƒ½æµ‹è¯•")
    test_group.add_argument("--test", type=str, help="è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶æˆ–ç›®å½•")
    
    # å·¥å…·é€‰é¡¹
    parser.add_argument("--lint", action="store_true", help="è¿è¡Œä»£ç æ£€æŸ¥")
    parser.add_argument("--format", action="store_true", help="æ ¼å¼åŒ–ä»£ç ")
    parser.add_argument("--install-deps", action="store_true", help="å®‰è£…æµ‹è¯•ä¾èµ–")
    parser.add_argument("--setup-env", action="store_true", help="è®¾ç½®æµ‹è¯•ç¯å¢ƒ")
    parser.add_argument("--report", action="store_true", help="ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šæ‘˜è¦")
    
    # è¿è¡Œé€‰é¡¹
    parser.add_argument("-v", "--verbose", action="store_true", help="è¯¦ç»†è¾“å‡º")
    parser.add_argument("--no-coverage", action="store_true", help="ç¦ç”¨è¦†ç›–ç‡æŠ¥å‘Š")
    parser.add_argument("--parallel", action="store_true", help="å¹¶è¡Œè¿è¡Œæµ‹è¯•")
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•é€‰é¡¹ï¼Œæ˜¾ç¤ºå¸®åŠ©
    if not any(vars(args).values()):
        parser.print_help()
        return
    
    success = True
    
    try:
        # è®¾ç½®æµ‹è¯•ç¯å¢ƒ
        if args.setup_env or args.all:
            setup_test_environment()
        
        # å®‰è£…ä¾èµ–
        if args.install_deps:
            install_dependencies()
        
        # æ ¼å¼åŒ–ä»£ç 
        if args.format:
            format_code()
        
        # ä»£ç æ£€æŸ¥
        if args.lint:
            if not run_linting():
                success = False
        
        # è¿è¡Œæµ‹è¯•
        coverage = not args.no_coverage
        
        if args.unit:
            if not run_unit_tests(args.verbose, coverage):
                success = False
        
        elif args.integration:
            if not run_integration_tests(args.verbose):
                success = False
        
        elif args.performance:
            if not run_performance_tests(args.verbose):
                success = False
        
        elif args.test:
            if not run_specific_test(args.test, args.verbose):
                success = False
        
        elif args.all:
            if not run_all_tests(args.verbose, coverage, args.parallel):
                success = False
        
        # ç”ŸæˆæŠ¥å‘Š
        if args.report or args.all:
            generate_test_report()
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        success = False
    
    except Exception as e:
        print(f"\n\nâŒ è¿è¡Œæµ‹è¯•æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        success = False
    
    # è¾“å‡ºæœ€ç»ˆç»“æœ
    print("\n" + "="*60)
    if success:
        print("ğŸ‰ æ‰€æœ‰æ“ä½œå®ŒæˆæˆåŠŸï¼")
        sys.exit(0)
    else:
        print("âŒ éƒ¨åˆ†æ“ä½œå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯")
        sys.exit(1)


if __name__ == "__main__":
    main()